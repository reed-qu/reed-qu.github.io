<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<title>SVM(二)拉格朗日对偶式</title>
<link href="https://reed-qu.github.io/theme/css/main.css" rel="stylesheet"/>
<link href="https://reed-qu.github.io/feeds/all.atom.xml" rel="alternate" title="[reed@blog ~]# _ Atom Feed" type="application/atom+xml"/>
</head>
<body class="home" id="index">
<header class="body" id="banner">
<h1><a href="https://reed-qu.github.io/">[reed@blog ~]# _ </a></h1>
<nav><ul>
<li class="active"><a href="https://reed-qu.github.io/category/machine-learning.html">machine learning</a></li>
</ul></nav>
</header><!-- /#banner -->
<section class="body" id="content">
<article>
<header>
<h1 class="entry-title">
<a href="https://reed-qu.github.io/svmer-la-ge-lang-ri-dui-ou-shi.html" rel="bookmark" title="Permalink to SVM(二)拉格朗日对偶式">SVM(二)拉格朗日对偶式</a></h1>
</header>
<div class="entry-content">
<footer class="post-info">
<abbr class="published" title="2020-01-24T21:11:26+08:00">
                Published: 2020-01-24
        </abbr>
<address class="vcard author">
                By                         <a class="url fn" href="https://reed-qu.github.io/author/reed.html">reed</a>
</address>
<p>In <a href="https://reed-qu.github.io/category/machine-learning.html">machine learning</a>.</p>
</footer><!-- /.post-info --> <blockquote>
<p>在 <a href="https://reed-qu.github.io/svmyi-cong-gan-zhi-ji-dao-svmsun-shi-han-shu.html"> SVM(一) </a>中从感知机说到硬间隔线性可分SVM的损失函数，此时损失函数是有约束条件的，无法直接计算导数为0时的参数，需要转换一下<strong>将目标函数和约束条件放到一个拉格朗日函数中</strong> ，这也就是为什么要构造拉格朗日函数，同时引出 <strong>拉格朗日对偶式</strong>，利用对偶式来求解，并且有利于引出核函数的思想，这里简单讨论一下SVM对偶式，并给出一个具体例子来思考原始问题和对偶问题的异同点。</p>
</blockquote>
<h2><strong>拉格朗日乘子</strong></h2>
<p>首先给定线性可分数据集  <span class="math">\( D={(x^{(1)}, y^{(1)}), (x^{(2)},y^{(2)}),\cdots,(x^{(N)}, y^{(N)})}\)</span>  ，其中  <span class="math">\( x^{(i)}\in R^n\)</span> ， <span class="math">\( y^{(i)}\in {-1, +1}\)</span> <span class="math">\( i = 1,2...,N\)</span>，观察SVM的损失函数，这是一个有约束条件的损失函数，也就是说要在 <strong>约束条件中找到目标函数的最小值</strong> ，即  <span class="math">\(\theta\)</span>  在满足  <span class="math">\( s.t. \space y^{(i)}(\theta^Tx^{(i)}+b)\geq1\)</span> 的基础上，最小化  <span class="math">\( \frac{1}{2}||\theta||^2\)</span>  ，而且是 <strong>不等式优化</strong></p>
<div class="math">$$
\begin{aligned}
    &amp;\mathop{min}_{\theta}\frac{1}{2}||\theta||^2\\
    &amp;s.t. \space y^{(i)}(\theta^Tx^{(i)}+b)\geq1
\end{aligned}\\
$$</div>
<p>针对此约束条件，考虑一般形式  <span class="math">\( f(x); \space\space s.t. \space g(x)\leq 0\)</span> ，有2种情况(图中绿色和蓝色的两种条件)</p>
<p><img class="image-process-article-image" src="/images/derivees/article-image/svm2_lagrange.jpg"/></p>
<p><strong>第一种</strong> ：图中蓝色  <span class="math">\( g(x)\leq 0\)</span>  部分，目标函数的 <strong>最优解在约束条件范围外</strong>，此时就相当于约束条件为  <span class="math">\( g(x)=0\)</span>  ，因为  <span class="math">\( g(x)&lt;0\)</span>  的部分相较于 <span class="math">\( g(x)=0\)</span>  肯定不是最优的(不够靠近目标函数的最优解嘛)，这里通过图中可以直观的看出， <strong>切线交点</strong> <span class="math">\( p^*\)</span> <strong>为最优点 ，是符合约束条件时的最小值，此时二者导数的方向相反</strong>，这里与2个注意点需要解释</p>
<ol>
<li><strong>为什么 <span class="math">\( p^*\)</span>  是切线交点？ </strong> 可以利用反证法的思想，假如  <span class="math">\( p^*\)</span>  不是切线交点，那么 <strong>一定有不为 <span class="math">\( 0\)</span>  的分量使得目标函数更小一些 </strong> ，那么显然那个点不是最优点，一直移动到  <span class="math">\( p^*\)</span>  点时为最优 </li>
<li><strong>为什么导数的方向相反？</strong> 首先  <span class="math">\( \bigtriangledown g(x)\)</span>  是垂直  <span class="math">\( g(x)=0\)</span>  的，而最小化的目标函数  <span class="math">\( \bigtriangledown f(x)\)</span>  在切线交点  <span class="math">\( p^*\)</span>  位置也是垂直  <span class="math">\( g(x)=0\)</span>  的， <strong>且相反的时候为最小值</strong> ， <strong>相同的时候为最大值</strong> ，这样一来就可以写成  <span class="math">\( \bigtriangledown f(x) + \lambda\bigtriangledown g(x) = 0\)</span>  ，这里  <span class="math">\( \lambda &gt; 0\)</span>  为一个系数， <strong>二者向量总是可以通过 <span class="math">\( \lambda\)</span>  这个系数转化为大小相等的 </strong> ，那么这样就可以构造出 </li>
</ol>
<div class="math">$$
L(x, \lambda) = f(x) + \lambda g(x)\\
$$</div>
<p>为什么要这么构造也很容易理解，对 <span class="math">\( L(x, \lambda)\)</span>  这个公式网回算，分别对  <span class="math">\( x, \lambda\)</span>  求导等于 <span class="math">\( 0\)</span></p>
<div class="math">$$
\begin{aligned}
    \frac{\partial L(x, \lambda)}{\partial x} &amp;= \bigtriangledown f(x) +\lambda\bigtriangledown g(x)&amp;= 0\\
    \frac{\partial L(x, \lambda)}{\partial \lambda} &amp;= g(x)&amp;= 0
\end{aligned}\\
$$</div>
<p><strong>此时正好满足 <span class="math">\( p^*\)</span>  点的位置二者导数相反且有一个  <span class="math">\( \lambda &gt; 0\)</span> 的系数关系和约束条件  <span class="math">\( g(x)=0\)</span>  ，函数  <span class="math">\( L(x, \lambda)\)</span> 叫做拉格朗日函数，  <span class="math">\( \lambda\)</span>  为拉格朗日乘子</strong></p>
<p><strong>第二种</strong> ：图中绿色  <span class="math">\( g'(x)\leq 0\)</span> 部分，目标函数的最优解在约束条件范围内，此时就更好处理了，其实此时约束条件相当于没有，所以  <span class="math">\( \lambda=0\)</span> ，综合这两种情况可以推导出</p>
<div class="math">$$
\begin{cases}
    \bigtriangledown f(x) +\lambda\bigtriangledown g(x) = 0 &amp; p^* point\\
    g(x)\leq 0 &amp; origin \space s.t. \\
    \lambda \geq 0 &amp; lagrange\space multiplier\\
    \lambda g(x) = 0 \end{cases}\\
$$</div>
<p>前三个很容易理解，上文中已经论证过了，但是  <span class="math">\( \lambda g(x) = 0\)</span>  这是个什么玩意？其实该等式是上面第一种情况 <span class="math">\( \lambda&gt;0 \space \&amp; \space g(x)=0\)</span>  和第二种情况  <span class="math">\(\lambda=0 \space \&amp; \space g(x)&lt;0\)</span>  整合出来的，这几个不等式就是 <strong>KKT(Karush-Kuhn-Tucker)条件</strong> ，这里需要注意的是： <strong>原优化条件是对可行解的约束，KKT条件是对最优解的约束</strong></p>
<p>此时针对最初的SVM损失函数来说，就可以转化成这样（很多的书中拉格朗日乘子会用  <span class="math">\( \alpha,\beta\)</span> 表示，这里因为最初是用  <span class="math">\( \lambda\)</span>  的所以一下都用  <span class="math">\( \lambda\)</span>  来表示）</p>
<div class="math">$$
\mathop{min}_{\theta,b}L(\theta, b, \lambda) = \frac{1}{2}||\theta||^2 + \sum_{i=1}^{N}{\lambda^{(i)}(1-y^{(i)}(\theta^Tx^{(i)}+b))} \\ s.t. \lambda^{(i)} \geq 0 ，\space i = 1,2...,N \\
$$</div>
<p>至此虽然是找到了  <span class="math">\( p^*\)</span> 点，但是求解还是很不容易，因为目前构造拉格朗日函数目的是优化方向一样，但是如何让朗格朗日函数和原始问题的解是一样的呢？这里多出来的 <span class="math">\(\lambda\)</span>  应该怎么处理掉呢？</p>
<h2><strong>拉格朗日对偶</strong></h2>
<p>为了解决上面拉格朗日函数的问题，首先直接的想法就是 <strong>让这个函数和原始问题一致</strong> ，然后求解这个拉格朗日函数就可以了，但是如今加进来一个 <span class="math">\( \lambda\)</span>  结合 <strong>KKT条件</strong> 如何让这两个问题一致呢？</p>
<p>首先的想法就是 <strong>在可行解区域内，也就是符合原始问题的约束条件，拉格朗日函数与原始问题一样；在可行解区域外，让拉格朗日函数取到 <span class="math">\( +\infty\)</span>  ，这样一来在求解  <span class="math">\( min\)</span>  问题的时候，这俩问题就一样了</strong>，所以可以构造函数，设其可行解区域为  <span class="math">\( \Omega\)</span> ，这里为了书写方便，不直接写SVM的形式，而是用更一般的形式目标函数为  <span class="math">\( f(x)\)</span>  ，约束条件为 <span class="math">\( g(x)\)</span></p>
<div class="math">$$
\Theta_p(x) = \mathop{max}_{\lambda}L(x, \lambda) = f(x) +\mathop{max}_{\lambda}[\sum_{i=1}^{N}{\lambda^{(i)}g(x)}]\\
$$</div>
<p>对于在可行解区域内  <span class="math">\( x\in\Omega\)</span>  ，根据  <span class="math">\( \lambda^{(i)}\geq0\)</span> ，  <span class="math">\( g(x^{(i)})\leq0\)</span>  可得</p>
<div class="math">$$
\mathop{max}_{\lambda}[\sum_{i=1}^{N}{\lambda^{(i)}g(x)}]=0\\
$$</div>
<p>如果不在可行解区域内  <span class="math">\( x\notin\Omega\)</span>  ，则至少有1组约束条件没有满足即  <span class="math">\(
g_j(x)&gt;0\)</span>  ，这时候调整  <span class="math">\( \lambda_j&gt;0\)</span>  ，取  <span class="math">\( +\infty\)</span> 就可以得到</p>
<div class="math">$$
\mathop{max}_{\lambda}[\sum_{i=1}^{N}{\lambda^{(i)}g(x)}]=+\infty\\
$$</div>
<p>此时我们构造的函数</p>
<div class="math">$$\Theta_p(x) = \mathop{max}_{\lambda}L(x, \lambda) =f(x) + \mathop{max}_{\lambda}[\sum_{i=1}^{N}{\lambda^{(i)}g(x)}]
$$</div>
<p>就与原始问题等价了，原始问题的约束条件也就没有了，然后再最小化  <span class="math">\( \Theta_p(x)\)</span>  即 <span class="math">\( min\space\Theta_p(x)\)</span>  ，注意此时问题为 <strong>极小极大问题</strong> ，拉格朗日对偶性就是可以把此时的<strong>极小极大问题转化为极大极小问题</strong> （此部分的证明个人水平有限，没看懂o(╯□╰)o）即 <strong>原始问题的对偶问题如下</strong></p>
<div class="math">$$
\mathop{max}_{\lambda}\mathop{min}_{\theta, b}L(\theta, b,\lambda)=\frac{1}{2}||\theta||^2+\sum_{i=1}^{N}{\lambda^{(i)}(1-y^{(i)}(\theta^Tx^{(i)}+b))}\\
$$</div>
<p>这样就先求解  <span class="math">\( min\)</span>  再求解  <span class="math">\( max\)</span>  ，求解  <span class="math">\(\mathop{min}_{\theta, b}L(\theta, b, \lambda)\)</span>  即 <strong>对 <span class="math">\( \theta,b\)</span> 求导为 </strong> <span class="math">\( 0\)</span> <strong>求得</strong></p>
<div class="math">$$
\begin{cases}
    \frac{\partial L}{\partial \theta} = \theta -\sum_{i=1}^{N}{\lambda^{(i)}y^{(i)}x^{(i)}}=0\\
    \frac{\partial L}{\partial b}=-\sum_{i=1}^{N}{\lambda^{(i)}y^{(i)}}=0
\end{cases}\\
$$</div>
<div class="math">$$
\begin{cases}
    \theta=\sum_{i=1}^{N}{\lambda^{(i)}y^{(i)}x^{(i)}}\\
    \sum_{i=1}^{N}{\lambda^{(i)}y^{(i)}}=0
\end{cases}\\
$$</div>
<p>将上式带入到原始问题的对偶问题中，此部分可能看起来比较麻烦，但是并不难，带入式子即可，这里的  <span class="math">\( i,j\)</span> 也只是为了区分而已，实际上并没什么区别</p>
<div class="math">$$
\begin{aligned}
    \mathop{min}_{\theta, b}L(\theta, b, \lambda) &amp;=\frac{1}{2}||\theta||^2+\sum_{i=1}^{N}{\lambda^{(i)}(1-y^{(i)}(\theta^Tx^{(i)}+b))}\\
    &amp;=\frac{1}{2}||\theta||^2-\sum_{i=1}^{N}{\lambda^{(i)}y^{(i)}\theta^Tx^{(i)}}-b\sum_{i=1}^{N}{\lambda^{(i)}y^{(i)}+\sum_{i=1}^{N}{\lambda^{(i)}}}\\
    &amp;=\frac{1}{2}\sum_{i=1}^{N}\sum_{j=1}^{N}{\lambda^{(i)}\lambda^{(j)}y^{(i)}y^{(j)}x^{(i)}x^{(j)}}-\sum_{i=1}^{N}\sum_{j=1}^{N}{\lambda^{(i)}\lambda^{(j)}y^{(i)}y^{(j)}x^{(i)}x^{(j)}}+\sum_{i=1}^{N}{\lambda^{(i)}}\\
    &amp;=\sum_{i=1}^{N}{\lambda^{(i)}}-\frac{1}{2}\sum_{i=1}^{N}\sum_{j=1}^{N}{\lambda^{(i)}\lambda^{(j)}y^{(i)}y^{(j)}x^{(i)}x^{(j)}}
\end{aligned}\\
$$</div>
<p>考虑上式的 <strong>极大化取负号变成最小化</strong> ，结合对  <span class="math">\( \theta,b\)</span>  求导为  <span class="math">\( 0\)</span>
和  <span class="math">\( \lambda\geq0\)</span>  就可以转化成，注意这里新增了一个约束条件为对  <span class="math">\( b\)</span>
求导为  <span class="math">\( 0\)</span>  时候的条件  <span class="math">\(\sum_{i=1}^{N}{\lambda^{(i)}y^{(i)}}=0\)</span></p>
<div class="math">$$
\begin{aligned}
    min \space &amp; \frac{1}{2}\sum_{i=1}^{N}\sum_{j=1}^{N}{\lambda^{(i)}\lambda^{(j)}y^{(i)}y^{(j)}x^{(i)}x^{(j)}}-\sum_{i=1}^{N}{\lambda^{(i)}}\\
    s.t. \space &amp;\sum_{i=1}^{N}{\lambda^{(i)}y^{(i)}}=0\\
    \space &amp; \lambda^{(i)}\geq0，i=1,2,\cdots,N
\end{aligned}\\
$$</div>
<p>考虑  <span class="math">\( \theta=\sum_{i=1}^{N}{\lambda^{(i)}y^{(i)}x^{(i)}}\)</span>  ，假如
<span class="math">\( \lambda^*=(\lambda^{*(1)},\lambda^{*(2)},...,\lambda^{*(l)})^T\)</span>
是对偶问题的解，那么肯定至少有1个  <span class="math">\( \lambda^{*(j)}&gt;0\)</span>  使得  <span class="math">\(y^{(j)}(\theta^*\cdot x^{(j)}+b^*)-1=0\)</span>  ，因为 <strong>间隔上至少存在1个支持向量</strong> ，同时考虑 <span class="math">\( (y^{(j)})^2=1，y^{(i)}\in{-1，+1}\)</span>  则有</p>
<div class="math">$$
\begin{aligned}
    &amp;y^{(j)}(\theta^*\cdot x^{(j)}+b^*)-1=0\\
    &amp;y^{(i)}(\sum_{i=1}^{N}{\lambda^{(i)}y^{(i)}x^{(i)}x^{(j)}+b^*})=(y^{(j)})^2\\
    &amp;b^*=y^{(j)}-\sum_{i=1}^{N}{\lambda^{*(i)}y^{(i)}(x^{(i)}\cdot x^{(j)})}
\end{aligned}\\
$$</div>
<p>至此  <span class="math">\( \theta^*，b^*\)</span>  都已经求得</p>
<div class="math">$$
\begin{cases}
    \theta^*=\sum_{i=1}^{N}{\lambda^{*(i)}y^{(i)}x^{(i)}}\\
    b^*=y^{(j)}-\sum_{i=1}^{N}{\lambda^{*(i)}y^{(i)}(x^{(i)}\cdot x^{(j)})}
\end{cases}\\
$$</div>
<p>所以分类决策函数就可以写成为如下形式，注意到这里还有前面的推导中  <span class="math">\( (x^{(i)}\cdot x^{(j)})\)</span>  都是<strong>单独括起来的</strong> ，其实是表示SVM在分类决策函数中只 <strong>依赖输入 <span class="math">\( x\)</span>  和训练样本的内积</strong>，这也是为什么对偶式更直接引出核函数，核函数所做的事情，就是把这个内积映射到高维空间中从而把线性不可分变为线性可分  </p>
<div class="math">$$
f(x)=sign(\sum_{i=1}^{N}{\lambda^{*(i)}y^{(i)}(x\cdot x^{(i)})+b^*})\\
$$</div>
<h2><strong>具体例子</strong></h2>
<p>通过上面的一通论证已经对SVM的对偶问题有了大概的理解，为了更清晰的看到是如何计算的，这里举个例子（例子来源李航老师的<a href="https://book.douban.com/subject/33437381/">《统计学习方法 第二版》</a>）分别计算原始问题和对偶问题</p>
<p>有3个样本点分别为  <span class="math">\( x^{(1)}=(3,3)^T; x^{(2)}=(4,3)^T;x^{(3)}=(1,1)^T\)</span>
，其中  <span class="math">\( x^{(1)},x^{(2)}\)</span>  为正例，  <span class="math">\( x^{(3)}\)</span> 为负例，求这样最大间隔分离超平面，作图如下</p>
<p><img class="image-process-article-image" src="/images/derivees/article-image/svm2_example.jpg"/></p>
<p><strong>首先求解原始问题</strong> ，这里为了书写公式方便，将上角标  <span class="math">\( i\)</span>  挪到下角标处</p>
<div class="math">$$
\begin{aligned}
    \mathop{min}_{\theta,b} \space &amp;\frac{1}{2}(\theta_1^2+\theta_2^2)\\
    s.t.\space&amp;3\theta_1+3\theta_2+b\geq1\\
    &amp;4\theta_1+3\theta_2+b\geq1\\
    &amp;-\theta_1-\theta2-b\geq1
\end{aligned}\\
$$</div>
<p>可解得  <span class="math">\( \theta_1=\theta_2=\frac{1}{2}，b=-2\)</span>  时取得最小值，所以最大间隔超平面如下，其中 <span class="math">\( x^{(1)},x^{(3)}\)</span>  为支持向量</p>
<div class="math">$$
\frac{1}{2}x_1+\frac{1}{2}x_2-2=0\\
$$</div>
<p><strong>然后再求解对偶问题</strong> ，  $ \theta^<em> , b^</em> $  都与  $ \lambda^<em> $ 相关，则先求解  $ \lambda^</em> $  ，得到了  $ \lambda^* $ 也就求得了超平面参数</p>
<div class="math">$$
\begin{equation} \begin{aligned}
    \mathop{min}_{\lambda} \space &amp;\frac{1}{2}\sum_{i-1}^{N}\sum_{j=1}^{N}{\lambda_i \lambda_j y_i y_j (x_i\cdot x_j)}-\sum_{i=1}^{N}{\lambda_i}\\
    &amp;=\frac{1}{2}(18\lambda_1^2+25\lambda_2^2+2\lambda_3^2+42\lambda_1 \lambda_2-12\lambda_1 \lambda_3-14\lambda_2 \lambda_3)-\lambda_1-\lambda_2-\lambda_3\\
    s.t.\space&amp;\lambda_1+\lambda_2-\lambda_3=0\\
    &amp;\lambda_i\geq0，i=1,2,3
\end{aligned} \end{equation}\\
$$</div>
<p><span class="math">\( \lambda_3=\lambda_1+\lambda_2\)</span> 带入目标函数中</p>
<div class="math">$$
\begin{aligned}
    J(\lambda_1, \lambda_2) &amp;= 4\lambda_1^2+\frac{13}{2}\lambda_2^2+10\lambda_1 \lambda_2-2\lambda_1-2\lambda_2\\
    \Rightarrow \space&amp; \begin{cases} \frac{\partial J}{\partial \lambda_1}=8\lambda_1+10\lambda_2-2=0\\
    \frac{\partial J}{\partial \lambda_2}=13\lambda_2+10\lambda_1-2=0 \end{cases}
\end{aligned}\\
$$</div>
<p>可以解出  <span class="math">\( J(\lambda_1, \lambda_2)\)</span>  在点  <span class="math">\((\frac{3}{2},-1)^T\)</span>  处取到极值，但是 <strong>注意到这里的 <span class="math">\( -1\)</span>  不满足约束条件 </strong> <span class="math">\( \lambda_2\geq0\)</span>  ，所以 <strong>此时最小值就不在边界内而是在边界上</strong> ，就要分别考虑 <span class="math">\( \lambda_1,\lambda_2\)</span>  为  <span class="math">\( 0\)</span>  的情况</p>
<div class="math">$$
\begin{cases}
    J(0, \frac{2}{13})=-\frac{2}{13} \space,for \space \lambda_1=0\\
    J(\frac{1}{4},0)=-\frac{1}{4} \space\space\space\space, for \space \lambda_2=0
\end{cases}\\
$$</div>
<p>所以  <span class="math">\( (\lambda_1, \lambda_2, \lambda_3)=(\frac{1}{4}, 0,\frac{1}{4})^T\)</span>  时对偶式取到极小值，通过拉格朗日乘子的特点就可以知道  <span class="math">\( x^{(1)},x^{(3)}\)</span> 为支持向量， <strong>因为该拉格朗日乘子不为 <span class="math">\( 0\)</span>  所以约束条件  <span class="math">\( g(x)=0\)</span> ，所以该点就是在间隔边界上的 </strong> ，然后再带入前面的  $ \theta^<em> , b^</em> $  求得</p>
<div class="math">$$
\begin{cases}
    \theta^*&amp;=\sum_{i=1}^{N}{\lambda^{*(i)}y^{(i)}x^{(i)}}&amp;=\frac{1}{4}\times1\times(3,3)^T+0\times1\times(4,3)^T-\frac{1}{4}\times1\times(1,1)^T&amp;=(\frac{1}{2},\frac{1}{2})^T\\
    b^*&amp;=y^{(1)}-\sum_{i=1}^{N}{\lambda^{*(1)}y^{(i)}(x^{(i)}\cdot x^{(1)})} &amp;=1-(\frac{1}{4}\times1\times18+0\times1\times21-\frac{1}{4}\times1\times6)&amp;=-2
\end{cases}\\
$$</div>
<p>与求解原始问题的一样的</p>
<h2><strong>总结</strong></h2>
<p>综上所述，硬间隔线性可分SVM对于给定的线性可分训练数据集，可以首先求解原始问题的对偶形式  <span class="math">\( \lambda^*\)</span> ，再计算分类决策函数的参数  <span class="math">\( \theta^*,b^*\)</span>  ，从而解决问题。但是截止到目前为止，都是<strong>假设数据的硬间隔线性可分的</strong> ，就说硬间隔是客观存在的，而在真实世界中往往有很多噪声，<strong>比如在间隔中存在杂乱的正例和负例，此时是找不出硬间隔的，这时候怎么办？</strong> 又或者 <strong>数据本身就不是线性可分的又该如何？</strong> 这些问题在下一次 <a href="https://reed-qu.github.io/svmsan-cong-ruan-jian-ge-dao-he-han-shu.html">SVM(三) </a> 中讨论。</p>
<hr/>
<p>😛</p>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>
</div><!-- /.entry-content -->
</article>
</section>
<section class="body" id="extras">
<div class="blogroll">
<h2>about me</h2>
<ul>
<li><a href="https://github.com/reedwave">github</a></li>
<li><a href="https://www.zhihu.com/people/reedqu">zhihu</a></li>
<li><a href="https://zhuanlan.zhihu.com/c_1098916898112212992">知乎专栏</a></li>
</ul>
</div><!-- /.blogroll -->
<div class="social">
<h2>social</h2>
<ul>
<li><a href="https://reed-qu.github.io/feeds/all.atom.xml" rel="alternate" type="application/atom+xml">atom feed</a></li>
</ul>
</div><!-- /.social -->
</section><!-- /#extras -->
<footer class="body" id="contentinfo">
<address class="vcard body" id="about">
                Proudly powered by <a href="http://getpelican.com/">Pelican</a>, which takes great advantage of <a href="http://python.org">Python</a>.
                </address><!-- /#about -->
<p>The theme is by <a href="http://coding.smashingmagazine.com/2009/08/04/designing-a-html-5-layout-from-scratch/">Smashing Magazine</a>, thanks!</p>
</footer><!-- /#contentinfo -->
</body>
</html>